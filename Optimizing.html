<!DOCTYPE html>
<html>
<head>
  <title>Optimizing your code</title>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="generator" content="pandoc" />




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">

  <base target="_blank">

  <script type="text/javascript">
    var SLIDE_CONFIG = {
      // Slide settings
      settings: {
                title: 'Optimizing your code',
                        useBuilds: true,
        usePrettify: true,
        enableSlideAreas: true,
        enableTouch: true,
                        favIcon: 'Optimizing_files/logo.png',
              },

      // Author information
      presenters: [
            {
        name:  'Pedro Ojeda' ,
        company: '',
        gplus: '',
        twitter: '',
        www: '',
        github: ''
      },
            ]
    };
  </script>

  <link href="site_libs/ioslides-13.5.1/fonts/fonts.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/default.css" rel="stylesheet" />
  <link href="site_libs/ioslides-13.5.1/theme/css/phone.css" rel="stylesheet" />
  <script src="site_libs/ioslides-13.5.1/js/modernizr.custom.45394.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/prettify.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-r.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/prettify/lang-yaml.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/hammer.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-controller.js"></script>
  <script src="site_libs/ioslides-13.5.1/js/slide-deck.js"></script>

  <style type="text/css">

    b, strong {
      font-weight: bold;
    }

    em {
      font-style: italic;
    }

    summary {
      display: list-item;
    }

    slides > slide {
      -webkit-transition: all 0.4s ease-in-out;
      -moz-transition: all 0.4s ease-in-out;
      -o-transition: all 0.4s ease-in-out;
      transition: all 0.4s ease-in-out;
    }

    .auto-fadein {
      -webkit-transition: opacity 0.6s ease-in;
      -webkit-transition-delay: 0.4s;
      -moz-transition: opacity 0.6s ease-in 0.4s;
      -o-transition: opacity 0.6s ease-in 0.4s;
      transition: opacity 0.6s ease-in 0.4s;
      opacity: 0;
    }
/* https://github.com/ropensci/plotly/pull/524#issuecomment-468142578 */
slide:not(.current) .plotly.html-widget{
  display: block;
}

    slides > slide:not(.nobackground):before {
      font-size: 12pt;
      content: "";
      position: absolute;
      bottom: 20px;
      left: 60px;
      background: url(Optimizing_files/logo.png) no-repeat 0 50%;
      -webkit-background-size: 30px 30px;
      -moz-background-size: 30px 30px;
      -o-background-size: 30px 30px;
      background-size: 30px 30px;
      padding-left: 40px;
      height: 30px;
      line-height: 1.9;
    }
  </style>

  <link rel="stylesheet" href="custom.css" type="text/css" />

</head>

<body style="opacity: 0">

<slides class="layout-widescreen">

  <slide class="title-slide segue nobackground">
        <aside class="gdbar"><img src="Optimizing_files/logo.png"></aside>
        <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
    <hgroup class="auto-fadein">
      <h1 data-config-title><!-- populated from slide_config.json --></h1>
      
      <p data-config-presenter><!-- populated from slide_config.json --></p>
            <p style="margin-top: 6px; margin-left: -2px;">Feb., 2021</p>
          </hgroup>
  </slide>

<slide class=""><hgroup><h2>Baseline</h2></hgroup><article  id="baseline">

<p>There are some tricks you can follow in order to get a faster code, we will use our Pi function from the previous topic as our baseline:</p>

<pre class = 'prettyprint lang-r'>sim &lt;- function(l) {
  c &lt;- rep(0,l); hits &lt;- 0
  pow2 &lt;- function(x) { x2 &lt;- sqrt( x[1]*x[1]+x[2]*x[2] ); return(x2) }
  for(i in 1:l){
             x = runif(2,-1,1)
     if( pow2(x) &lt;=1 ){
                  hits &lt;- hits + 1
        }
        dens &lt;- hits/i; pi_partial = dens*4; c[i] = pi_partial
    }
   return(c)
}</pre>

</article></slide><slide class=""><hgroup><h2>Baseline</h2></hgroup><article  id="baseline-1">

<p>the execution time of this function for 100,000 iterations is</p>

<pre class = 'prettyprint lang-r'>size &lt;- 100000
system.time(
   res &lt;- sim(size)
)</pre>

<pre >##    user  system elapsed 
##    0.52    0.00    0.56</pre>

</article></slide><slide class=""><hgroup><h2>Vectorization</h2></hgroup><article  id="vectorization">

<p>If we vectorize the code we obtain a better performance:</p>

<pre class = 'prettyprint lang-r'>simv &lt;- function(l) {
  set.seed(0.234234)
  x=runif(l); y=runif(l)
  z=sqrt(x^2 + y^2)
  resl &lt;- length(which(z&lt;=1))*4/length(z)
  return(resl)
}</pre>

</article></slide><slide class=""><hgroup><h2>Vectorization</h2></hgroup><article  id="vectorization-1">

<pre class = 'prettyprint lang-r'>size &lt;- 100000
system.time(
  res &lt;- simv(size)
)</pre>

<pre >##    user  system elapsed 
##    0.02    0.00    0.01</pre>

<p>a message from this example is that loops are expensive in R and vectorization can help to improve the performance of the code.</p>

<p>Common vector operations: \(+\), \(-\), \(/\), \(*\), \(\% * \%\).</p>

</article></slide><slide class=""><hgroup><h2>Memory pre-allocation</h2></hgroup><article  id="memory-pre-allocation">

<pre class = 'prettyprint lang-r'>N &lt;- 1E5
data1 &lt;- 1 
system.time({
    for (j in 2:N) {
      data1 &lt;- c(data1, data1[j-1] + sample(-5:5, size=1))
    }
  })</pre>

<pre >##    user  system elapsed 
##   11.35    0.17   11.57</pre>

</article></slide><slide class=""><hgroup><h2>Memory pre-allocation</h2></hgroup><article  id="memory-pre-allocation-1">

<pre class = 'prettyprint lang-r'>data2 &lt;- numeric(N)
data2[1] &lt;- 1
system.time({
  for (j in 2:N) {
    data2[j] &lt;- data2[j-1] + sample(-5:5, size=1)
  }
})</pre>

<pre >##    user  system elapsed 
##    0.52    0.00    0.52</pre>

<p>This example shows that pre-allocating memory reduces the execution time.</p>

</article></slide><slide class=""><hgroup><h2>Using Data Frames with caution</h2></hgroup><article  id="using-data-frames-with-caution">

<pre class = 'prettyprint lang-r'>data1 &lt;- rnorm(1E4*1000)
dim(data1) &lt;- c(1E4,1000)
dataf &lt;- data.frame(data1)
system.time(data2 &lt;- rowSums(dataf))</pre>

<pre >##    user  system elapsed 
##    0.05    0.00    0.04</pre>

</article></slide><slide class=""><hgroup><h2>Using Data Frames with caution</h2></hgroup><article  id="using-data-frames-with-caution-1">

<pre class = 'prettyprint lang-r'>data1 &lt;- rnorm(1E4*1000)
dim(data1) &lt;- c(1E4,1000)
system.time(data1 &lt;- rowSums(data1))</pre>

<pre >##    user  system elapsed 
##    0.03    0.00    0.03</pre>

<p>Then, it is more efficient to use matrices upon doing numerical calculations rather than Data Frames.</p>

</article></slide><slide class=""><hgroup><h2>Different implementations of functions</h2></hgroup><article  id="different-implementations-of-functions">

<p>Principal components analysis</p>

<img width="500px" src='Images/pca_analysis.png' title='fig:'/><p class='caption'>J. Chem. Inf. Mod., 57, 826-834 (2017)</p>

</article></slide><slide class=""><hgroup><h2>Different implementations of functions</h2></hgroup><article  id="different-implementations-of-functions-1">

<pre class = 'prettyprint lang-r'>data &lt;- rnorm(1E5*100)
dim(data) &lt;- c(1E5,100)
system.time(prcomp_data &lt;- prcomp(data))</pre>

<pre >##    user  system elapsed 
##    3.97    0.02    3.99</pre>

<pre class = 'prettyprint lang-r'>system.time(princomp_data &lt;- princomp(data))</pre>

<pre >##    user  system elapsed 
##    2.14    0.03    2.18</pre>

</article></slide><slide class=""><hgroup><h2>Compiling your functions</h2></hgroup><article  id="compiling-your-functions">

<pre class = 'prettyprint lang-r'>library(microbenchmark)
library(compiler)

sim &lt;- function(l) {
  c &lt;- rep(0,l); hits &lt;- 0
  pow2 &lt;- function(x) { x2 &lt;- sqrt( x[1]*x[1]+x[2]*x[2] ); return(x2) }
  for(i in 1:l){
             x = runif(2,-1,1)
     if( pow2(x) &lt;=1 ){
                  hits &lt;- hits + 1
        }
        dens &lt;- hits/i; pi_partial = dens*4; c[i] = pi_partial
         }
   
   return(c)
}</pre>

</article></slide><slide class=""><hgroup><h2>Compiling your functions</h2></hgroup><article  id="compiling-your-functions-1">

<pre class = 'prettyprint lang-r'>sim.comp0 &lt;- cmpfun(sim, options=list(optimize=0))
sim.comp1 &lt;- cmpfun(sim, options=list(optimize=1))
sim.comp2 &lt;- cmpfun(sim, options=list(optimize=2))
sim.comp3 &lt;- cmpfun(sim, options=list(optimize=3))

size &lt;- 100000
bench &lt;- microbenchmark(sim(size), sim.comp0(size), sim.comp1(size), sim.comp2(size), 
                        sim.comp3(size))</pre>

</article></slide><slide class=""><hgroup><h2>Compiling your functions</h2></hgroup><article  id="compiling-your-functions-2">

<pre class = 'prettyprint lang-r'>bench</pre>

<pre >## Unit: milliseconds
##             expr      min       lq     mean   median       uq      max neval
##        sim(size) 229.0572 249.8000 269.2744 264.9132 276.1020 420.4646   100
##  sim.comp0(size) 681.6037 731.4833 771.8331 754.8584 794.9337 952.1181   100
##  sim.comp1(size) 311.5354 335.8135 357.5988 343.3766 374.7464 496.5831   100
##  sim.comp2(size) 228.3147 257.0486 278.7223 270.1176 290.8073 416.5595   100
##  sim.comp3(size) 224.6233 248.4780 270.8613 263.6723 279.3110 474.7394   100</pre>

</article></slide><slide class=""><hgroup><h2>Compiling your functions</h2></hgroup><article  id="compiling-your-functions-3">

<p>visualize the results:</p>

<pre class = 'prettyprint lang-r'>library(ggplot2)
autoplot(bench)</pre>

<img width="450px" src='Images/violin.png' title='fig:'/><p class='caption'>Violin Plot</p>

</article></slide><slide class=""><hgroup><h2>Just in time compilation</h2></hgroup><article  id="just-in-time-compilation">

<pre class = 'prettyprint lang-r'>library(compiler)
enableJIT(level=3)</pre>

<pre >## [1] 3</pre>

<pre class = 'prettyprint lang-r'>bench &lt;- microbenchmark(sim(size))
bench</pre>

<pre >## Unit: milliseconds
##       expr      min       lq     mean   median       uq      max neval
##  sim(size) 241.0523 251.2682 270.5526 268.3233 275.1775 361.9124   100</pre>

</article></slide><slide class=""><hgroup><h2>Rcpp package</h2></hgroup><article  id="rcpp-package">

<p><strong>Rcpp</strong> package allows you to write your code in C++ that could be called within a R script:</p>

<pre class = 'prettyprint lang-r'>library(Rcpp)</pre>

<pre class = 'prettyprint lang-r'>cppFunction(&#39;int mul(int a, int b, int c) {
  int mul = a * b * c;
  return mul;
}&#39;)
mul</pre>

<pre >## function (a, b, c) 
## .Call(&lt;pointer: 0x00000000712815a0&gt;, a, b, c)</pre>

<pre class = 'prettyprint lang-r'>mul(2,4,6)</pre>

<pre >## [1] 48</pre>

</article></slide><slide class=""><hgroup><h2>Following cases work on Kebnekaise only:</h2></hgroup><article  id="following-cases-work-on-kebnekaise-only">

<h3>Calling external functions (Fortran)</h3>

<pre class = 'prettyprint lang-r'>subroutine pifunc(n)
implicit none
integer, parameter :: seed = 86456
integer     :: i,n,hits
real        :: x,y,r,pival
call srand(seed)
hits = 0
do i=1,n
   x = rand()
   y = rand()
   r = sqrt(x*x + y*y)
   if(r &lt;= 1) then 
       hits = hits + 1
   endif
enddo
pival = 4.0d0*hits/(1.0*n)
end subroutine pifunc</pre>

</article></slide><slide class=""><hgroup><h2>Following cases work on Kebnekaise only:</h2></hgroup><article  id="following-cases-work-on-kebnekaise-only-1">

<h3>Calling external functions</h3>

<p>One compiles the function using standard compilers (Linux, Kebnekaise):</p>

<pre class = 'prettyprint lang-r'>gfortran -shared -fPIC -o picalc pi.f90</pre>

<pre class = 'prettyprint lang-r'>size &lt;- 100000

dyn.load(&quot;picalc&quot;)
is.loaded(&quot;pifunc&quot;)
.Fortran(&quot;pifunc&quot;, n = as.integer(size))</pre>

</article></slide><slide class=""><hgroup><h2>Following cases that run on Kebnekaise:</h2></hgroup><article  id="following-cases-that-run-on-kebnekaise">

<h3>Calling external functions</h3>

<p>now we can benchmark our functions:</p>

<pre class = 'prettyprint lang-r'>library(microbenchmark)
bench &lt;- microbenchmark(sim(size), .Fortran(&quot;pifunc&quot;, n = as.integer(size)))
bench

Unit: milliseconds
                        expr        min         lq       mean     median         uq 
          sim(size) 229.596323 234.312380 240.501156 236.034249 238.871773 316.289453
 .Fortran(&quot;pifunc&quot;)   4.136534   4.155587   4.239279   4.188102   4.261413   5.747752</pre>

<p>Vectorized code performance was ~10 ms.</p>

</article></slide><slide class=""><hgroup><h2>Following cases that run on Kebnekaise:</h2></hgroup><article  id="following-cases-that-run-on-kebnekaise-1">

<h3>Calling Julia functions</h3>

<pre class = 'prettyprint lang-r'>ml GCC/8.2.0-2.31.1  OpenMPI/3.1.3; ml R/3.6.0; ml julia/1.1.0
library(JuliaCall) #install.packages(&quot;JuliaCall&quot;)
julia_setup()
julia_command(&quot;
function sim(l)
  hits = 0
  for i = 1:l
    x = rand()*2 - 1
    y = rand()*2 - 1
    r = x*x + y*y
    if r &lt; 1.0 
      hits += 1
    end
  end
  pi_partial = (hits/l)*4
end&quot;)
invisible(julia_call(&quot;sim&quot;, size))</pre>

</article></slide><slide class=""><hgroup><h2>Following cases that run on Kebnekaise:</h2></hgroup><article  id="following-cases-that-run-on-kebnekaise-2">

<h3>Calling Julia functions</h3>

<pre class = 'prettyprint lang-r'>library(microbenchmark)
bench &lt;- microbenchmark(sim(size), julia_call(&quot;sim&quot;, size))
bench

Unit: microseconds
                    expr        min         lq        mean     median         uq  
               sim(size) 230284.183 237486.927 246621.8263 244825.215 250872.803
 julia_call(&quot;sim&quot;, size)    400.051    426.745    490.8316    496.087    542.283</pre>

</article></slide><slide class=""><hgroup><h2>Summary</h2></hgroup><article  id="summary">

<ul>
<li><p>Profile/benchmark your initial code to have a baseline</p></li>
<li><p>Some techniques that can help you to get a faster code are</p>

<ul>
<li>vectorization</li>
<li>pre-allocating objects</li>
<li>use matrices instead of Data Frames (Data Tables?)</li>
<li>check different functions/package implementations</li>
<li>use byte compiled code</li>
<li>if extra improvement is needed, it is time to consider <em>Rccp</em> or external function calls</li>
<li>calling <em>Julia</em> functions can also be helpful</li>
</ul></li>
</ul>

</article></slide><slide class=""><hgroup><h2>References</h2></hgroup><article  id="references">

<ul>
<li>R High Performance Programming. Aloysius, Lim; William, Tjhi. Packt Publishing, 2015.</li>
<li><a href='http://adv-r.had.co.nz/Profiling.html#vectorise' title=''>http://adv-r.had.co.nz/Profiling.html#vectorise</a></li>
<li><a href='http://adv-r.had.co.nz/Functionals.html#functionals' title=''>http://adv-r.had.co.nz/Functionals.html#functionals</a></li>
<li><a href='https://helloacm.com/r-programming-tutorial-how-to-compute-pi-using-monte-carlo-in-r/' title=''>Pi vectorization</a></li>
<li>Advanced R, Hadley Wickham, Taylor &amp; Francis Group</li>
</ul>

<p><a href='index.html' title=''>Return to Index</a></p></article></slide>


  <slide class="backdrop"></slide>

</slides>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!-- map slide visiblity events into shiny -->
<script>
  (function() {
    if (window.jQuery) {
       window.jQuery(document).on('slideleave', function(e) {
         window.jQuery(e.target).trigger('hidden');
      });
       window.jQuery(document).on('slideenter', function(e) {
         window.jQuery(e.target).trigger('shown');
      });
    }
  })();
</script>

</body>
</html>
