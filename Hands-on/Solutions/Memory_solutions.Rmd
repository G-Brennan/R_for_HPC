---
title: "Solutions"
author: "Pedro Ojeda, Birgitte Bryds√∂, Mirko Myllykoski"
date: "Feb., 2021"
output: html_document
---

## 1. Exercise 

Using the functions sumcol() and colSums() from the Profiling section to obtain a memory 
profiling summary using *Rprof*. Replace *FIXME* strings with the appropriate R code.

```{r eval=TRUE}

A <- matrix(1.0, 5000, 5000)     #Matrix initialization

sumcol <- function(B) {
  l <- ncol(B)  #obtain the number of columns
  colsm <- rep(0,l) #create a vector to save the sums
  
  for(j in 1:l){  
    s <- 0
    for(i in 1:l){
      s <- s + B[i,j]
    }
    colsm[i] <- s
  }
  return(colsm)
}

#Profiling sumcol() function
Rprof("Rprof-mema.out", memory.profiling=TRUE)
res1 <- sumcol(A)
Rprof(NULL)
summaryRprof("Rprof-mema.out", memory="both")

#Profiling colSums() function
Rprof("Rprof-memb.out", memory.profiling=TRUE)
res2 <- colSums(A)
Rprof(NULL)
summaryRprof("Rprof-memb.out", memory="both")
```

What is the total memory used by *sumcol()* and *colSums()*? Results vary slightly
depending on your architecture.

## 2. Exercise

Using the setup from the lecture on *bigmemory* package for the large array *bm*,
compute the mean and standard deviation of each column for a matrix with a size
$10^7 \times 3$ and using chunks of $10^6$.

First, we create the backing file *bm* and descriptor *bm.desc* for the big matrix:

```{r eval=TRUE}
library(bigmemory)
set.seed(1234)
bm <- big.matrix(1e7, 3, backingfile = "bm", backingpath = getwd())
bm
```

Now, work with chunks of data. Initialize the big matrix's columns with according to
probability distributions:

```{r eval=TRUE}
chunksize <- 1e6
start <- 1
while (start <= nrow(bm)) {
  end <- min(start + chunksize -1, nrow(bm))
  chunksize <- end - start + 1
  bm[start:end, 1] <- rpois(chunksize, 1e3)
  bm[start:end, 2] <- sample(0:1, chunksize, TRUE, c(0.7,0.3))
  bm[start:end, 3] <- runif(chunksize, 0, 1e5)
  start <- start + chunksize
}
```

means:

```{r eval=TRUE}
col.sums <- numeric(3)
chunksize <- 1e6
start <- 1
while (start <= nrow(bm)) {
  end <- min(start + chunksize -1, nrow(bm))
  col.sums <- col.sums + colSums(bm[start:end,])
  start <- start + chunksize
}
col.means <- col.sums / nrow(bm)
col.means
```


standard deviations:

```{r eval=TRUE}
col.sq.dev <- numeric(3)
chunksize <- 1e6
start <- 1
while (start <= nrow(bm)) {
  end <- min(start + chunksize -1, nrow(bm))
  col.sq.dev <- col.sq.dev + rowSums((t(bm[start:end,]) - col.means) ^2)
  start <- start + chunksize
}
col.var <- col.sq.dev/(nrow(bm)-1)
col.sd <- sqrt(col.var)
col.sd
```

Note: *bigmemory* package is used for larger matrices than in the present 
example. Here, I chose a small size for the matrix to avoid filling your 
disk.


## 3. Exercise

The two following *for loops* use a cutoff of 0.05 to assing the value **NA** to the vector
elements:

```{r}
library(tictoc)
x <- runif(1e+08)   #change this value to 1e+06, 1e+07, 1e+08         

#plain loop
tic()
for (i in 1:length(x)) {
  if (x[i] < 0.05) {
    x[i] <- NA
  }
}
toc()

x <- runif(1e+08)   #change this value to 1e+06, 1e+07, 1e+08
#below is the vectorized counterpart:
tic()
x[which(x < 0.05)] <- NA 
toc()
```

compare the execution times of both functions using vector sizes of 1e+06, 1e+07, and 1e+08. 
Which function showed the best performance?

The vectorized loop performs better for the vector sizes studied here.

Now, use *gcinfo* to analyze the memory used by both codes (plain loop and the vectorized one) as follows: 

```{r eval=TRUE}
#rm(list = ls())
x <- runif(1e+07)
check <- gcinfo(TRUE)
if(check == FALSE) check <- gcinfo(TRUE)

#Plain loop
  for (i in 1:length(x)) {
    if (x[i] < 0.05) {
      x[i] <- NA
    }
  }

gcinfo(FALSE)
```

```{r eval=TRUE}
x <- runif(1e+07)
check <- gcinfo(TRUE)
if(check == FALSE) check <- gcinfo(TRUE)

x[which(x < 0.05)] <- NA 

gcinfo(FALSE)
```

which code uses more memory? Based on this result, when would it be 
more appropriate to use the plain loop and when the vectorized code? 
**Note: in order to run the codes for the plain loop and the vectorized 
code, one needs to start with a fresh R session (Ctrl+Shift+F10) after 
running each of block of code**

                          
Based on this data, the vectorized function had the best performance. 
However, one needs to keep in mind that the memory 
usage of the vectorized one could be twice of the initial vector **x**
which is not the case in the plain loop.
